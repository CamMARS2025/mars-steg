Model:
  model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"  # The model name
  model_save_path: "./experiments/models"  # The path to save the model
  load_precision_mode: "4bits" # Options: ["4bits","8bits","full"]
  lora: true # false
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  lora_bias: "none" #sticking to example : https://huggingface.co/docs/trl/main/en/peft_integration

Inference:
    log_with: 'wandb'
    batch_size: 10
    seed: 42
    num_trials : 10
    is_peft_model: True
    load_lora_from_path_wandb: "rich-water-7_model_0_step_149"

Generation:
  min_length: 0
  # top_k: 0.0
  top_p: 0.95
  num_beams: 1
  temperature: 0.6
  do_sample: true
  #pad_token_id: 0
  bos_token_id: 151646
  eos_token_id: 151643
  max_new_tokens: 700
  return_prompt: False
  generate_ref_response: False
  use_cache : True
