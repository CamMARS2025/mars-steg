Search.setIndex({"alltitles": {"Description:": [[1, "description"], [5, "description"], [5, "id14"]], "MARS Steg documentation": [[0, null]], "Module Name: base_task.py": [[5, "module-name-base-task-py"]], "Module Name: config.py": [[1, "module-name-config-py"]], "Module Name: neural_assessor.py": [[5, "module-name-neural-assessor-py"]], "Module contents": [[1, "module-mars_steg"], [2, "module-mars_steg.dataset"], [3, "module-mars_steg.language"], [4, "module-mars_steg.model"], [5, "module-mars_steg.task"], [6, "module-mars_steg.utils"]], "Submodules": [[1, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"], [6, "submodules"]], "Subpackages": [[1, "subpackages"]], "mars_steg": [[7, null]], "mars_steg package": [[1, null]], "mars_steg.benchmark module": [[1, "module-mars_steg.benchmark"]], "mars_steg.config module": [[1, "module-mars_steg.config"]], "mars_steg.cot_evaluation module": [[1, "mars-steg-cot-evaluation-module"]], "mars_steg.dataset package": [[2, null]], "mars_steg.language package": [[3, null]], "mars_steg.language.base_language_aspect module": [[3, "module-mars_steg.language.base_language_aspect"]], "mars_steg.model package": [[4, null]], "mars_steg.model.base_model module": [[4, "module-mars_steg.model.base_model"]], "mars_steg.model.deepseek module": [[4, "module-mars_steg.model.deepseek"]], "mars_steg.model.gpt module": [[4, "module-mars_steg.model.gpt"]], "mars_steg.model.llama module": [[4, "module-mars_steg.model.llama"]], "mars_steg.model.loader module": [[4, "module-mars_steg.model.loader"]], "mars_steg.neural_assessor_model_testing module": [[1, "mars-steg-neural-assessor-model-testing-module"]], "mars_steg.task package": [[5, null]], "mars_steg.task.base_task module": [[5, "module-mars_steg.task.base_task"]], "mars_steg.task.neural_assessor module": [[5, "module-mars_steg.task.neural_assessor"]], "mars_steg.train_dataset_task module": [[1, "mars-steg-train-dataset-task-module"]], "mars_steg.utils package": [[6, null]], "mars_steg.utils.answer_extraction module": [[6, "module-mars_steg.utils.answer_extraction"]], "mars_steg.utils.common module": [[6, "module-mars_steg.utils.common"]], "mars_steg.utils.exceptions module": [[6, "module-mars_steg.utils.exceptions"]], "mars_steg.utils.math_equivalence module": [[6, "module-mars_steg.utils.math_equivalence"]], "mars_steg.utils.openai_api_helpers module": [[6, "module-mars_steg.utils.openai_api_helpers"]], "mars_steg.utils.plot module": [[6, "module-mars_steg.utils.plot"]], "mars_steg.utils.prompt_data module": [[6, "module-mars_steg.utils.prompt_data"]], "mars_steg.utils.score module": [[6, "module-mars_steg.utils.score"]]}, "docnames": ["index", "mars_steg", "mars_steg.dataset", "mars_steg.language", "mars_steg.model", "mars_steg.task", "mars_steg.utils", "modules"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["index.rst", "mars_steg.rst", "mars_steg.dataset.rst", "mars_steg.language.rst", "mars_steg.model.rst", "mars_steg.task.rst", "mars_steg.utils.rst", "modules.rst"], "indexentries": {"__getattribute__() (mars_steg.config.promptconfig method)": [[1, "mars_steg.config.PromptConfig.__getattribute__", false]], "adam_epsilon (mars_steg.config.optimizerconfig attribute)": [[1, "mars_steg.config.OptimizerConfig.adam_epsilon", false]], "answer_format_instruction (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.answer_format_instruction", false]], "answer_format_instruction_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.answer_format_instruction_dir", false]], "append() (mars_steg.utils.prompt_data.batchpromptdata method)": [[6, "mars_steg.utils.prompt_data.BatchPromptData.append", false]], "assessor_transcript (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.assessor_transcript", false]], "basemodel (class in mars_steg.model.base_model)": [[4, "mars_steg.model.base_model.BaseModel", false]], "batch_size (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.batch_size", false]], "batch_size (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.batch_size", false]], "batchize_conversation() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.batchize_conversation", false]], "batchpromptdata (class in mars_steg.utils.prompt_data)": [[6, "mars_steg.utils.prompt_data.BatchPromptData", false]], "bos_token_id (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.bos_token_id", false]], "check_score() (in module mars_steg.utils.score)": [[6, "mars_steg.utils.score.check_score", false]], "compatible_tasks (mars_steg.language.base_language_aspect.languageaspect attribute)": [[3, "mars_steg.language.base_language_aspect.LanguageAspect.compatible_tasks", false]], "configloader (class in mars_steg.config)": [[1, "mars_steg.config.ConfigLoader", false]], "convert_batch_prompt_into_conversation_template() (mars_steg.task.neural_assessor.problemsolutionassessor method)": [[5, "id17", false], [5, "mars_steg.task.neural_assessor.ProblemSolutionAssessor.convert_batch_prompt_into_conversation_template", false]], "cot_instruction (mars_steg.task.base_task.task property)": [[5, "id0", false]], "cot_instruction() (mars_steg.task.base_task.task method)": [[5, "mars_steg.task.base_task.Task.cot_instruction", false]], "cot_prompt (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.cot_prompt", false]], "cot_transcript (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.cot_transcript", false]], "cotgapsummary (class in mars_steg.utils.score)": [[6, "mars_steg.utils.score.CoTGapSummary", false]], "create_ref_model (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.create_ref_model", false]], "datainfo (class in mars_steg.utils.prompt_data)": [[6, "mars_steg.utils.prompt_data.DataInfo", false]], "dataset_class_kwargs (mars_steg.config.experimentargs attribute)": [[1, "mars_steg.config.ExperimentArgs.dataset_class_kwargs", false]], "dataset_class_name (mars_steg.config.experimentargs attribute)": [[1, "mars_steg.config.ExperimentArgs.dataset_class_name", false]], "deepseek_r1_1pt5b (class in mars_steg.model.deepseek)": [[4, "mars_steg.model.deepseek.DeepSeek_R1_1pt5B", false]], "do_sample (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.do_sample", false]], "duplicate() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.duplicate", false]], "emptylanguageaspect (class in mars_steg.language.base_language_aspect)": [[3, "mars_steg.language.base_language_aspect.EmptyLanguageAspect", false]], "end_output_token (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.end_output_token", false]], "end_output_token_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.end_output_token_dir", false]], "end_scratchpad_token (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.end_scratchpad_token", false]], "end_scratchpad_token_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.end_scratchpad_token_dir", false]], "eos_token_id (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.eos_token_id", false]], "evaluate_cot_gap (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.evaluate_cot_gap", false]], "evaluate_cot_gap_summary() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.evaluate_cot_gap_summary", false]], "experimentargs (class in mars_steg.config)": [[1, "mars_steg.config.ExperimentArgs", false]], "extract_boolean_overseer_or_assessor_answer() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.extract_boolean_overseer_or_assessor_answer", false]], "extract_cots() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.extract_cots", false]], "extract_floatingpoint_overseer_or_assessor_answer() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.extract_floatingpoint_overseer_or_assessor_answer", false]], "extract_neural_assessor_answers() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.extract_neural_assessor_answers", false]], "extract_neural_overseer_answers() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.extract_neural_overseer_answers", false]], "extract_section() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.extract_section", false]], "extracted_assessor_answer (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.extracted_assessor_answer", false]], "extracted_cot (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.extracted_cot", false]], "extracted_final_answer_with_cot (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.extracted_final_answer_with_cot", false]], "extracted_final_answer_without_cot (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.extracted_final_answer_without_cot", false]], "extracted_overseer_answer (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.extracted_overseer_answer", false]], "fixeddatasetdatainfo (class in mars_steg.utils.prompt_data)": [[6, "mars_steg.utils.prompt_data.FixedDatasetDataInfo", false]], "from_file() (mars_steg.config.promptconfig class method)": [[1, "id4", false]], "from_file() (mars_steg.config.promptconfig method)": [[1, "mars_steg.config.PromptConfig.from_file", false]], "from_yaml() (mars_steg.config.experimentargs class method)": [[1, "id2", false]], "from_yaml() (mars_steg.config.experimentargs method)": [[1, "mars_steg.config.ExperimentArgs.from_yaml", false]], "full_generate() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.full_generate", false]], "full_generate() (mars_steg.model.deepseek.deepseek_r1_1pt5b method)": [[4, "mars_steg.model.deepseek.DeepSeek_R1_1pt5B.full_generate", false]], "gamebasedtask (class in mars_steg.task.base_task)": [[5, "mars_steg.task.base_task.GameBasedTask", false]], "generate_full_prompt() (mars_steg.task.base_task.task method)": [[5, "id1", false], [5, "mars_steg.task.base_task.Task.generate_full_prompt", false]], "generate_info() (mars_steg.task.base_task.task method)": [[5, "id2", false], [5, "mars_steg.task.base_task.Task.generate_info", false]], "generate_info() (mars_steg.task.base_task.torchdatasettask method)": [[5, "id9", false], [5, "mars_steg.task.base_task.TorchDatasetTask.generate_info", false]], "generate_prompt() (mars_steg.task.base_task.task method)": [[5, "id3", false], [5, "mars_steg.task.base_task.Task.generate_prompt", false]], "generate_ref_response (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.generate_ref_response", false]], "generationconfig (class in mars_steg.config)": [[1, "mars_steg.config.GenerationConfig", false]], "get_assessor_generated_answers() (mars_steg.task.neural_assessor.problemsolutionassessor method)": [[5, "id18", false], [5, "mars_steg.task.neural_assessor.ProblemSolutionAssessor.get_assessor_generated_answers", false]], "get_batch_job() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.get_batch_job", false]], "get_dataloaders_and_ref_model() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.get_dataloaders_and_ref_model", false]], "get_device() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.get_device", false]], "get_info_from_batch_element() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.get_info_from_batch_element", false]], "get_language_score() (mars_steg.language.base_language_aspect.emptylanguageaspect method)": [[3, "mars_steg.language.base_language_aspect.EmptyLanguageAspect.get_language_score", false]], "get_language_score() (mars_steg.language.base_language_aspect.languageaspect method)": [[3, "mars_steg.language.base_language_aspect.LanguageAspect.get_language_score", false]], "get_message() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.get_message", false]], "get_message() (mars_steg.model.deepseek.deepseek_r1_1pt5b method)": [[4, "mars_steg.model.deepseek.DeepSeek_R1_1pt5B.get_message", false]], "get_message() (mars_steg.model.gpt.gpt2model method)": [[4, "mars_steg.model.gpt.GPT2Model.get_message", false]], "get_message() (mars_steg.model.llama.llama_31_8b_instruct method)": [[4, "mars_steg.model.llama.Llama_31_8B_Instruct.get_message", false]], "get_model() (in module mars_steg.model.loader)": [[4, "mars_steg.model.loader.get_model", false]], "get_model() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.get_model", false]], "get_optimizer() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.get_optimizer", false]], "get_rewards_and_training_datas() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.get_rewards_and_training_datas", false]], "get_task_score() (mars_steg.task.base_task.task method)": [[5, "id4", false], [5, "mars_steg.task.base_task.Task.get_task_score", false]], "get_tokenizer() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.get_tokenizer", false]], "get_true_answers_from_batch_prompt_data() (mars_steg.task.base_task.torchdatasettask method)": [[5, "id10", false], [5, "mars_steg.task.base_task.TorchDatasetTask.get_true_answers_from_batch_prompt_data", false]], "gpt2model (class in mars_steg.model.gpt)": [[4, "mars_steg.model.gpt.GPT2Model", false]], "gradient_accumulation_steps (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.gradient_accumulation_steps", false]], "idx (mars_steg.utils.prompt_data.fixeddatasetdatainfo attribute)": [[6, "mars_steg.utils.prompt_data.FixedDatasetDataInfo.idx", false]], "index() (mars_steg.utils.prompt_data.batchpromptdata method)": [[6, "mars_steg.utils.prompt_data.BatchPromptData.index", false]], "info (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.info", false]], "is_equiv() (in module mars_steg.utils.math_equivalence)": [[6, "mars_steg.utils.math_equivalence.is_equiv", false]], "jsonl_line() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.jsonl_line", false]], "languageaspect (class in mars_steg.language.base_language_aspect)": [[3, "mars_steg.language.base_language_aspect.LanguageAspect", false]], "learning_rate (mars_steg.config.optimizerconfig attribute)": [[1, "mars_steg.config.OptimizerConfig.learning_rate", false]], "length_sampler (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.length_sampler", false]], "llama_31_8b_instruct (class in mars_steg.model.llama)": [[4, "mars_steg.model.llama.Llama_31_8B_Instruct", false]], "llama_32_1b_instruct (class in mars_steg.model.llama)": [[4, "mars_steg.model.llama.Llama_32_1B_Instruct", false]], "llmtranscriptextractionerror": [[6, "mars_steg.utils.exceptions.LLMTranscriptExtractionError", false]], "load_config() (mars_steg.config.configloader method)": [[1, "mars_steg.config.ConfigLoader.load_config", false]], "load_config() (mars_steg.config.configloader static method)": [[1, "id0", false]], "load_config() (mars_steg.config.promptconfigloader method)": [[1, "mars_steg.config.PromptConfigLoader.load_config", false]], "load_config() (mars_steg.config.promptconfigloader static method)": [[1, "id5", false]], "load_model() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.load_model", false]], "load_precision_mode (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.load_precision_mode", false]], "load_yaml() (in module mars_steg.config)": [[1, "mars_steg.config.load_yaml", false]], "log_loading() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.log_loading", false]], "log_with (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.log_with", false]], "lora (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.lora", false]], "lora_alpha (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.lora_alpha", false]], "lora_bias (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.lora_bias", false]], "lora_dropout (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.lora_dropout", false]], "lora_params (mars_steg.config.modelconfig property)": [[1, "mars_steg.config.ModelConfig.lora_params", false]], "lora_r (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.lora_r", false]], "make_jsonl_batch_file() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.make_jsonl_batch_file", false]], "mars_steg": [[1, "module-mars_steg", false]], "mars_steg.benchmark": [[1, "module-mars_steg.benchmark", false]], "mars_steg.config": [[1, "module-mars_steg.config", false]], "mars_steg.dataset": [[2, "module-mars_steg.dataset", false]], "mars_steg.language": [[3, "module-mars_steg.language", false]], "mars_steg.language.base_language_aspect": [[3, "module-mars_steg.language.base_language_aspect", false]], "mars_steg.model": [[4, "module-mars_steg.model", false]], "mars_steg.model.base_model": [[4, "module-mars_steg.model.base_model", false]], "mars_steg.model.deepseek": [[4, "module-mars_steg.model.deepseek", false]], "mars_steg.model.gpt": [[4, "module-mars_steg.model.gpt", false]], "mars_steg.model.llama": [[4, "module-mars_steg.model.llama", false]], "mars_steg.model.loader": [[4, "module-mars_steg.model.loader", false]], "mars_steg.task": [[5, "module-mars_steg.task", false]], "mars_steg.task.base_task": [[5, "module-mars_steg.task.base_task", false]], "mars_steg.task.neural_assessor": [[5, "module-mars_steg.task.neural_assessor", false]], "mars_steg.utils": [[6, "module-mars_steg.utils", false]], "mars_steg.utils.answer_extraction": [[6, "module-mars_steg.utils.answer_extraction", false]], "mars_steg.utils.common": [[6, "module-mars_steg.utils.common", false]], "mars_steg.utils.exceptions": [[6, "module-mars_steg.utils.exceptions", false]], "mars_steg.utils.math_equivalence": [[6, "module-mars_steg.utils.math_equivalence", false]], "mars_steg.utils.openai_api_helpers": [[6, "module-mars_steg.utils.openai_api_helpers", false]], "mars_steg.utils.plot": [[6, "module-mars_steg.utils.plot", false]], "mars_steg.utils.prompt_data": [[6, "module-mars_steg.utils.prompt_data", false]], "mars_steg.utils.score": [[6, "module-mars_steg.utils.score", false]], "max_grad_norm (mars_steg.config.optimizerconfig attribute)": [[1, "mars_steg.config.OptimizerConfig.max_grad_norm", false]], "max_new_tokens (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.max_new_tokens", false]], "min_length (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.min_length", false]], "mini_batch_size (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.mini_batch_size", false]], "model_name (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.model_name", false]], "model_save_path (mars_steg.config.modelconfig attribute)": [[1, "mars_steg.config.ModelConfig.model_save_path", false]], "modelconfig (class in mars_steg.config)": [[1, "mars_steg.config.ModelConfig", false]], "module": [[1, "module-mars_steg", false], [1, "module-mars_steg.benchmark", false], [1, "module-mars_steg.config", false], [2, "module-mars_steg.dataset", false], [3, "module-mars_steg.language", false], [3, "module-mars_steg.language.base_language_aspect", false], [4, "module-mars_steg.model", false], [4, "module-mars_steg.model.base_model", false], [4, "module-mars_steg.model.deepseek", false], [4, "module-mars_steg.model.gpt", false], [4, "module-mars_steg.model.llama", false], [4, "module-mars_steg.model.loader", false], [5, "module-mars_steg.task", false], [5, "module-mars_steg.task.base_task", false], [5, "module-mars_steg.task.neural_assessor", false], [6, "module-mars_steg.utils", false], [6, "module-mars_steg.utils.answer_extraction", false], [6, "module-mars_steg.utils.common", false], [6, "module-mars_steg.utils.exceptions", false], [6, "module-mars_steg.utils.math_equivalence", false], [6, "module-mars_steg.utils.openai_api_helpers", false], [6, "module-mars_steg.utils.plot", false], [6, "module-mars_steg.utils.prompt_data", false], [6, "module-mars_steg.utils.score", false]], "name (mars_steg.task.base_task.task attribute)": [[5, "mars_steg.task.base_task.Task.name", false]], "neural_assessor_from_batch_prompt_data() (mars_steg.task.base_task.torchdatasettask method)": [[5, "id11", false], [5, "mars_steg.task.base_task.TorchDatasetTask.neural_assessor_from_batch_prompt_data", false]], "neural_assessor_system_prompt (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_assessor_system_prompt", false]], "neural_assessor_system_prompt_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_assessor_system_prompt_dir", false]], "neural_assessor_user_prompt_template (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_assessor_user_prompt_template", false]], "neural_assessor_user_prompt_template_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_assessor_user_prompt_template_dir", false]], "neural_overseer_system_prompt (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_overseer_system_prompt", false]], "neural_overseer_system_prompt_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_overseer_system_prompt_dir", false]], "neural_overseer_user_prompt_template (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_overseer_user_prompt_template", false]], "neural_overseer_user_prompt_template_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.neural_overseer_user_prompt_template_dir", false]], "no_cot_instruction (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.no_cot_instruction", false]], "no_cot_instruction (mars_steg.task.base_task.task property)": [[5, "id5", false]], "no_cot_instruction() (mars_steg.task.base_task.task method)": [[5, "mars_steg.task.base_task.Task.no_cot_instruction", false]], "no_cot_instruction_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.no_cot_instruction_dir", false]], "no_cot_prompt (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.no_cot_prompt", false]], "no_cot_transcript (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.no_cot_transcript", false]], "num_beams (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.num_beams", false]], "num_eval_episodes (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.num_eval_episodes", false]], "num_train_epochs (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.num_train_epochs", false]], "number_of_evaluations (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.number_of_evaluations", false]], "number_shared_layers_for_ref_model (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.number_shared_layers_for_ref_model", false]], "optimizer_name (mars_steg.config.optimizerconfig attribute)": [[1, "mars_steg.config.OptimizerConfig.optimizer_name", false]], "optimizerconfig (class in mars_steg.config)": [[1, "mars_steg.config.OptimizerConfig", false]], "overseer_transcript (mars_steg.utils.prompt_data.promptdata attribute)": [[6, "mars_steg.utils.prompt_data.PromptData.overseer_transcript", false]], "p1_bid (mars_steg.utils.prompt_data.sequentialpricetaskdatainfo attribute)": [[6, "mars_steg.utils.prompt_data.SequentialPriceTaskDataInfo.p1_bid", false]], "p2_true_cost (mars_steg.utils.prompt_data.sequentialpricetaskdatainfo attribute)": [[6, "mars_steg.utils.prompt_data.SequentialPriceTaskDataInfo.p2_true_cost", false]], "pad_token_id (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.pad_token_id", false]], "parse_model_output() (in module mars_steg.utils.answer_extraction)": [[6, "mars_steg.utils.answer_extraction.parse_model_output", false]], "penalisation_class_kwargs (mars_steg.config.experimentargs attribute)": [[1, "mars_steg.config.ExperimentArgs.penalisation_class_kwargs", false]], "penalisation_class_name (mars_steg.config.experimentargs attribute)": [[1, "mars_steg.config.ExperimentArgs.penalisation_class_name", false]], "ppo_epochs (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.ppo_epochs", false]], "problemsolutionassessor (class in mars_steg.task.neural_assessor)": [[5, "mars_steg.task.neural_assessor.ProblemSolutionAssessor", false]], "prompt_data_collate_fn() (mars_steg.task.base_task.torchdatasettask method)": [[5, "id12", false], [5, "mars_steg.task.base_task.TorchDatasetTask.prompt_data_collate_fn", false]], "promptconfig (class in mars_steg.config)": [[1, "mars_steg.config.PromptConfig", false]], "promptconfigloader (class in mars_steg.config)": [[1, "mars_steg.config.PromptConfigLoader", false]], "promptdata (class in mars_steg.utils.prompt_data)": [[6, "mars_steg.utils.prompt_data.PromptData", false]], "read_batch_output_file() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.read_batch_output_file", false]], "recruit_neural_assessor() (mars_steg.task.base_task.task method)": [[5, "id6", false], [5, "mars_steg.task.base_task.Task.recruit_neural_assessor", false]], "recruit_neural_overseer() (mars_steg.language.base_language_aspect.languageaspect method)": [[3, "mars_steg.language.base_language_aspect.LanguageAspect.recruit_neural_overseer", false]], "return_prompt (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.return_prompt", false]], "reward() (mars_steg.task.base_task.task method)": [[5, "id7", false], [5, "mars_steg.task.base_task.Task.reward", false]], "reward_from_transcript() (mars_steg.task.base_task.task method)": [[5, "id8", false], [5, "mars_steg.task.base_task.Task.reward_from_transcript", false]], "save() (mars_steg.utils.prompt_data.batchpromptdata method)": [[6, "mars_steg.utils.prompt_data.BatchPromptData.save", false]], "save() (mars_steg.utils.prompt_data.promptdata method)": [[6, "mars_steg.utils.prompt_data.PromptData.save", false]], "save_config() (mars_steg.config.configloader method)": [[1, "mars_steg.config.ConfigLoader.save_config", false]], "save_config() (mars_steg.config.configloader static method)": [[1, "id1", false]], "save_frequency (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.save_frequency", false]], "seed (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.seed", false]], "sequentialpricetaskdatainfo (class in mars_steg.utils.prompt_data)": [[6, "mars_steg.utils.prompt_data.SequentialPriceTaskDataInfo", false]], "set_seed() (in module mars_steg.utils.common)": [[6, "mars_steg.utils.common.set_seed", false]], "single_query() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.single_query", false]], "start_output_token (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.start_output_token", false]], "start_output_token_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.start_output_token_dir", false]], "start_scratchpad_token (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.start_scratchpad_token", false]], "start_scratchpad_token_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.start_scratchpad_token_dir", false]], "submit_batch_file() (in module mars_steg.utils.openai_api_helpers)": [[6, "mars_steg.utils.openai_api_helpers.submit_batch_file", false]], "sum_examples (mars_steg.utils.score.cotgapsummary attribute)": [[6, "mars_steg.utils.score.CoTGapSummary.sum_examples", false]], "sum_extracted_with_cot (mars_steg.utils.score.cotgapsummary attribute)": [[6, "mars_steg.utils.score.CoTGapSummary.sum_extracted_with_cot", false]], "sum_extracted_without_cot (mars_steg.utils.score.cotgapsummary attribute)": [[6, "mars_steg.utils.score.CoTGapSummary.sum_extracted_without_cot", false]], "sum_reward_with_cot (mars_steg.utils.score.cotgapsummary attribute)": [[6, "mars_steg.utils.score.CoTGapSummary.sum_reward_with_cot", false]], "sum_reward_without_cot (mars_steg.utils.score.cotgapsummary attribute)": [[6, "mars_steg.utils.score.CoTGapSummary.sum_reward_without_cot", false]], "summary (mars_steg.utils.score.cotgapsummary property)": [[6, "mars_steg.utils.score.CoTGapSummary.summary", false]], "system_prompt (mars_steg.task.base_task.task attribute)": [[5, "mars_steg.task.base_task.Task.system_prompt", false]], "task (class in mars_steg.task.base_task)": [[5, "mars_steg.task.base_task.Task", false]], "task_description (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.task_description", false]], "task_description_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.task_description_dir", false]], "task_examples (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.task_examples", false]], "task_examples_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.task_examples_dir", false]], "temperature (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.temperature", false]], "test_equiv_decimal_fraction() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_equiv_decimal_fraction", false]], "test_equiv_formats() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_equiv_formats", false]], "test_equiv_symbols() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_equiv_symbols", false]], "test_multiple_answers_1() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_multiple_answers_1", false]], "test_multiple_answers_2() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_multiple_answers_2", false]], "test_multiple_answers_3() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_multiple_answers_3", false]], "test_multiple_answers_4() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_multiple_answers_4", false]], "test_multiple_answers_5() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_multiple_answers_5", false]], "test_multiple_answers_6() (mars_steg.utils.math_equivalence.testnormalize method)": [[6, "mars_steg.utils.math_equivalence.TestNormalize.test_multiple_answers_6", false]], "test_train_split() (mars_steg.task.base_task.torchdatasettask method)": [[5, "id13", false], [5, "mars_steg.task.base_task.TorchDatasetTask.test_train_split", false]], "testnormalize (class in mars_steg.utils.math_equivalence)": [[6, "mars_steg.utils.math_equivalence.TestNormalize", false]], "to_dict() (mars_steg.config.generationconfig method)": [[1, "mars_steg.config.GenerationConfig.to_dict", false]], "to_generation_dict() (mars_steg.config.generationconfig method)": [[1, "mars_steg.config.GenerationConfig.to_generation_dict", false]], "to_training_dict() (mars_steg.config.generationconfig method)": [[1, "mars_steg.config.GenerationConfig.to_training_dict", false]], "top_k (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.top_k", false]], "top_p (mars_steg.config.generationconfig attribute)": [[1, "mars_steg.config.GenerationConfig.top_p", false]], "torchdatasettask (class in mars_steg.task.base_task)": [[5, "mars_steg.task.base_task.TorchDatasetTask", false]], "train_proportion (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.train_proportion", false]], "trainconfig (class in mars_steg.config)": [[1, "mars_steg.config.TrainConfig", false]], "transform_conversation() (mars_steg.model.base_model.basemodel method)": [[4, "mars_steg.model.base_model.BaseModel.transform_conversation", false]], "transform_conversation() (mars_steg.model.deepseek.deepseek_r1_1pt5b method)": [[4, "mars_steg.model.deepseek.DeepSeek_R1_1pt5B.transform_conversation", false]], "uses_local_neural_assessor (mars_steg.task.base_task.task attribute)": [[5, "mars_steg.task.base_task.Task.uses_local_neural_assessor", false]], "uses_local_neural_overseer (mars_steg.language.base_language_aspect.emptylanguageaspect attribute)": [[3, "mars_steg.language.base_language_aspect.EmptyLanguageAspect.uses_local_neural_overseer", false]], "uses_local_neural_overseer (mars_steg.language.base_language_aspect.languageaspect attribute)": [[3, "mars_steg.language.base_language_aspect.LanguageAspect.uses_local_neural_overseer", false]], "validation_proportion (mars_steg.config.trainconfig attribute)": [[1, "mars_steg.config.TrainConfig.validation_proportion", false]], "warmup_steps (mars_steg.config.optimizerconfig attribute)": [[1, "mars_steg.config.OptimizerConfig.warmup_steps", false]], "weight_decay (mars_steg.config.optimizerconfig attribute)": [[1, "mars_steg.config.OptimizerConfig.weight_decay", false]], "with_cot_instruction (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.with_cot_instruction", false]], "with_cot_instruction_dir (mars_steg.config.promptconfig attribute)": [[1, "mars_steg.config.PromptConfig.with_cot_instruction_dir", false]]}, "objects": {"": [[1, 0, 0, "-", "mars_steg"]], "mars_steg": [[1, 0, 0, "-", "benchmark"], [1, 0, 0, "-", "config"], [2, 0, 0, "-", "dataset"], [3, 0, 0, "-", "language"], [4, 0, 0, "-", "model"], [5, 0, 0, "-", "task"], [6, 0, 0, "-", "utils"]], "mars_steg.config": [[1, 1, 1, "", "ConfigLoader"], [1, 1, 1, "", "ExperimentArgs"], [1, 1, 1, "", "GenerationConfig"], [1, 1, 1, "", "ModelConfig"], [1, 1, 1, "", "OptimizerConfig"], [1, 1, 1, "", "PromptConfig"], [1, 1, 1, "", "PromptConfigLoader"], [1, 1, 1, "", "TrainConfig"], [1, 5, 1, "", "load_yaml"]], "mars_steg.config.ConfigLoader": [[1, 2, 1, "id0", "load_config"], [1, 2, 1, "id1", "save_config"]], "mars_steg.config.ExperimentArgs": [[1, 3, 1, "", "dataset_class_kwargs"], [1, 3, 1, "", "dataset_class_name"], [1, 2, 1, "id2", "from_yaml"], [1, 3, 1, "", "penalisation_class_kwargs"], [1, 3, 1, "", "penalisation_class_name"]], "mars_steg.config.GenerationConfig": [[1, 3, 1, "", "batch_size"], [1, 3, 1, "", "bos_token_id"], [1, 3, 1, "", "do_sample"], [1, 3, 1, "", "eos_token_id"], [1, 3, 1, "", "generate_ref_response"], [1, 3, 1, "", "length_sampler"], [1, 3, 1, "", "max_new_tokens"], [1, 3, 1, "", "min_length"], [1, 3, 1, "", "num_beams"], [1, 3, 1, "", "pad_token_id"], [1, 3, 1, "", "return_prompt"], [1, 3, 1, "", "temperature"], [1, 2, 1, "", "to_dict"], [1, 2, 1, "", "to_generation_dict"], [1, 2, 1, "", "to_training_dict"], [1, 3, 1, "", "top_k"], [1, 3, 1, "", "top_p"]], "mars_steg.config.ModelConfig": [[1, 3, 1, "", "load_precision_mode"], [1, 3, 1, "", "lora"], [1, 3, 1, "", "lora_alpha"], [1, 3, 1, "", "lora_bias"], [1, 3, 1, "", "lora_dropout"], [1, 4, 1, "", "lora_params"], [1, 3, 1, "", "lora_r"], [1, 3, 1, "", "model_name"], [1, 3, 1, "", "model_save_path"]], "mars_steg.config.OptimizerConfig": [[1, 3, 1, "", "adam_epsilon"], [1, 3, 1, "", "learning_rate"], [1, 3, 1, "", "max_grad_norm"], [1, 3, 1, "", "optimizer_name"], [1, 3, 1, "", "warmup_steps"], [1, 3, 1, "", "weight_decay"]], "mars_steg.config.PromptConfig": [[1, 2, 1, "", "__getattribute__"], [1, 3, 1, "", "answer_format_instruction"], [1, 3, 1, "", "answer_format_instruction_dir"], [1, 3, 1, "", "end_output_token"], [1, 3, 1, "", "end_output_token_dir"], [1, 3, 1, "", "end_scratchpad_token"], [1, 3, 1, "", "end_scratchpad_token_dir"], [1, 2, 1, "id4", "from_file"], [1, 3, 1, "", "neural_assessor_system_prompt"], [1, 3, 1, "", "neural_assessor_system_prompt_dir"], [1, 3, 1, "", "neural_assessor_user_prompt_template"], [1, 3, 1, "", "neural_assessor_user_prompt_template_dir"], [1, 3, 1, "", "neural_overseer_system_prompt"], [1, 3, 1, "", "neural_overseer_system_prompt_dir"], [1, 3, 1, "", "neural_overseer_user_prompt_template"], [1, 3, 1, "", "neural_overseer_user_prompt_template_dir"], [1, 3, 1, "", "no_cot_instruction"], [1, 3, 1, "", "no_cot_instruction_dir"], [1, 3, 1, "", "start_output_token"], [1, 3, 1, "", "start_output_token_dir"], [1, 3, 1, "", "start_scratchpad_token"], [1, 3, 1, "", "start_scratchpad_token_dir"], [1, 3, 1, "", "task_description"], [1, 3, 1, "", "task_description_dir"], [1, 3, 1, "", "task_examples"], [1, 3, 1, "", "task_examples_dir"], [1, 3, 1, "", "with_cot_instruction"], [1, 3, 1, "", "with_cot_instruction_dir"]], "mars_steg.config.PromptConfigLoader": [[1, 2, 1, "id5", "load_config"]], "mars_steg.config.TrainConfig": [[1, 3, 1, "", "batch_size"], [1, 3, 1, "", "create_ref_model"], [1, 3, 1, "", "evaluate_cot_gap"], [1, 3, 1, "", "gradient_accumulation_steps"], [1, 3, 1, "", "log_with"], [1, 3, 1, "", "mini_batch_size"], [1, 3, 1, "", "num_eval_episodes"], [1, 3, 1, "", "num_train_epochs"], [1, 3, 1, "", "number_of_evaluations"], [1, 3, 1, "", "number_shared_layers_for_ref_model"], [1, 3, 1, "", "ppo_epochs"], [1, 3, 1, "", "save_frequency"], [1, 3, 1, "", "seed"], [1, 3, 1, "", "train_proportion"], [1, 3, 1, "", "validation_proportion"]], "mars_steg.language": [[3, 0, 0, "-", "base_language_aspect"]], "mars_steg.language.base_language_aspect": [[3, 1, 1, "", "EmptyLanguageAspect"], [3, 1, 1, "", "LanguageAspect"]], "mars_steg.language.base_language_aspect.EmptyLanguageAspect": [[3, 2, 1, "", "get_language_score"], [3, 3, 1, "", "uses_local_neural_overseer"]], "mars_steg.language.base_language_aspect.LanguageAspect": [[3, 3, 1, "", "compatible_tasks"], [3, 2, 1, "", "get_language_score"], [3, 2, 1, "", "recruit_neural_overseer"], [3, 3, 1, "", "uses_local_neural_overseer"]], "mars_steg.model": [[4, 0, 0, "-", "base_model"], [4, 0, 0, "-", "deepseek"], [4, 0, 0, "-", "gpt"], [4, 0, 0, "-", "llama"], [4, 0, 0, "-", "loader"]], "mars_steg.model.base_model": [[4, 1, 1, "", "BaseModel"]], "mars_steg.model.base_model.BaseModel": [[4, 2, 1, "", "batchize_conversation"], [4, 2, 1, "", "duplicate"], [4, 2, 1, "", "full_generate"], [4, 2, 1, "", "get_message"], [4, 2, 1, "", "load_model"], [4, 2, 1, "", "log_loading"], [4, 2, 1, "", "transform_conversation"]], "mars_steg.model.deepseek": [[4, 1, 1, "", "DeepSeek_R1_1pt5B"]], "mars_steg.model.deepseek.DeepSeek_R1_1pt5B": [[4, 2, 1, "", "full_generate"], [4, 2, 1, "", "get_message"], [4, 2, 1, "", "transform_conversation"]], "mars_steg.model.gpt": [[4, 1, 1, "", "GPT2Model"]], "mars_steg.model.gpt.GPT2Model": [[4, 2, 1, "", "get_message"]], "mars_steg.model.llama": [[4, 1, 1, "", "Llama_31_8B_Instruct"], [4, 1, 1, "", "Llama_32_1B_Instruct"]], "mars_steg.model.llama.Llama_31_8B_Instruct": [[4, 2, 1, "", "get_message"]], "mars_steg.model.loader": [[4, 5, 1, "", "get_model"]], "mars_steg.task": [[5, 0, 0, "-", "base_task"], [5, 0, 0, "-", "neural_assessor"]], "mars_steg.task.base_task": [[5, 1, 1, "", "GameBasedTask"], [5, 1, 1, "", "Task"], [5, 1, 1, "", "TorchDatasetTask"]], "mars_steg.task.base_task.Task": [[5, 4, 1, "id0", "cot_instruction"], [5, 2, 1, "id1", "generate_full_prompt"], [5, 2, 1, "id2", "generate_info"], [5, 2, 1, "id3", "generate_prompt"], [5, 2, 1, "id4", "get_task_score"], [5, 3, 1, "", "name"], [5, 4, 1, "id5", "no_cot_instruction"], [5, 2, 1, "id6", "recruit_neural_assessor"], [5, 2, 1, "id7", "reward"], [5, 2, 1, "id8", "reward_from_transcript"], [5, 3, 1, "", "system_prompt"], [5, 3, 1, "", "uses_local_neural_assessor"]], "mars_steg.task.base_task.TorchDatasetTask": [[5, 2, 1, "id9", "generate_info"], [5, 2, 1, "id10", "get_true_answers_from_batch_prompt_data"], [5, 2, 1, "id11", "neural_assessor_from_batch_prompt_data"], [5, 2, 1, "id12", "prompt_data_collate_fn"], [5, 2, 1, "id13", "test_train_split"]], "mars_steg.task.neural_assessor": [[5, 1, 1, "", "ProblemSolutionAssessor"]], "mars_steg.task.neural_assessor.ProblemSolutionAssessor": [[5, 2, 1, "id17", "convert_batch_prompt_into_conversation_template"], [5, 2, 1, "id18", "get_assessor_generated_answers"]], "mars_steg.utils": [[6, 0, 0, "-", "answer_extraction"], [6, 0, 0, "-", "common"], [6, 0, 0, "-", "exceptions"], [6, 0, 0, "-", "math_equivalence"], [6, 0, 0, "-", "openai_api_helpers"], [6, 0, 0, "-", "plot"], [6, 0, 0, "-", "prompt_data"], [6, 0, 0, "-", "score"]], "mars_steg.utils.answer_extraction": [[6, 5, 1, "", "extract_boolean_overseer_or_assessor_answer"], [6, 5, 1, "", "extract_cots"], [6, 5, 1, "", "extract_floatingpoint_overseer_or_assessor_answer"], [6, 5, 1, "", "extract_neural_assessor_answers"], [6, 5, 1, "", "extract_neural_overseer_answers"], [6, 5, 1, "", "extract_section"], [6, 5, 1, "", "parse_model_output"]], "mars_steg.utils.common": [[6, 5, 1, "", "evaluate_cot_gap_summary"], [6, 5, 1, "", "get_dataloaders_and_ref_model"], [6, 5, 1, "", "get_device"], [6, 5, 1, "", "get_model"], [6, 5, 1, "", "get_optimizer"], [6, 5, 1, "", "get_rewards_and_training_datas"], [6, 5, 1, "", "get_tokenizer"], [6, 5, 1, "", "set_seed"]], "mars_steg.utils.exceptions": [[6, 6, 1, "", "LLMTranscriptExtractionError"]], "mars_steg.utils.math_equivalence": [[6, 1, 1, "", "TestNormalize"], [6, 5, 1, "", "is_equiv"]], "mars_steg.utils.math_equivalence.TestNormalize": [[6, 2, 1, "", "test_equiv_decimal_fraction"], [6, 2, 1, "", "test_equiv_formats"], [6, 2, 1, "", "test_equiv_symbols"], [6, 2, 1, "", "test_multiple_answers_1"], [6, 2, 1, "", "test_multiple_answers_2"], [6, 2, 1, "", "test_multiple_answers_3"], [6, 2, 1, "", "test_multiple_answers_4"], [6, 2, 1, "", "test_multiple_answers_5"], [6, 2, 1, "", "test_multiple_answers_6"]], "mars_steg.utils.openai_api_helpers": [[6, 5, 1, "", "get_batch_job"], [6, 5, 1, "", "get_info_from_batch_element"], [6, 5, 1, "", "jsonl_line"], [6, 5, 1, "", "make_jsonl_batch_file"], [6, 5, 1, "", "read_batch_output_file"], [6, 5, 1, "", "single_query"], [6, 5, 1, "", "submit_batch_file"]], "mars_steg.utils.prompt_data": [[6, 1, 1, "", "BatchPromptData"], [6, 1, 1, "", "DataInfo"], [6, 1, 1, "", "FixedDatasetDataInfo"], [6, 1, 1, "", "PromptData"], [6, 1, 1, "", "SequentialPriceTaskDataInfo"]], "mars_steg.utils.prompt_data.BatchPromptData": [[6, 2, 1, "", "append"], [6, 2, 1, "", "index"], [6, 2, 1, "", "save"]], "mars_steg.utils.prompt_data.FixedDatasetDataInfo": [[6, 3, 1, "", "idx"]], "mars_steg.utils.prompt_data.PromptData": [[6, 3, 1, "", "assessor_transcript"], [6, 3, 1, "", "cot_prompt"], [6, 3, 1, "", "cot_transcript"], [6, 3, 1, "", "extracted_assessor_answer"], [6, 3, 1, "", "extracted_cot"], [6, 3, 1, "", "extracted_final_answer_with_cot"], [6, 3, 1, "", "extracted_final_answer_without_cot"], [6, 3, 1, "", "extracted_overseer_answer"], [6, 3, 1, "", "info"], [6, 3, 1, "", "no_cot_prompt"], [6, 3, 1, "", "no_cot_transcript"], [6, 3, 1, "", "overseer_transcript"], [6, 2, 1, "", "save"]], "mars_steg.utils.prompt_data.SequentialPriceTaskDataInfo": [[6, 3, 1, "", "p1_bid"], [6, 3, 1, "", "p2_true_cost"]], "mars_steg.utils.score": [[6, 1, 1, "", "CoTGapSummary"], [6, 5, 1, "", "check_score"]], "mars_steg.utils.score.CoTGapSummary": [[6, 3, 1, "", "sum_examples"], [6, 3, 1, "", "sum_extracted_with_cot"], [6, 3, 1, "", "sum_extracted_without_cot"], [6, 3, 1, "", "sum_reward_with_cot"], [6, 3, 1, "", "sum_reward_without_cot"], [6, 4, 1, "", "summary"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"], "6": ["py", "exception", "Python exception"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function", "6": "py:exception"}, "terms": {"": [1, 3, 5], "0": [3, 5, 6], "07": 6, "1": [1, 3, 5, 6], "18": 6, "2024": 6, "42": 6, "4o": 6, "A": [3, 5, 6], "By": 5, "For": 5, "If": [3, 5, 6], "It": 5, "NOS": 6, "No": [1, 5], "THE": 1, "The": [1, 5, 6], "_": 6, "__getattribute__": [1, 7], "__name": 1, "abc": 6, "abl": 6, "about": 5, "abstract": [3, 4, 5], "accumul": 1, "ad": 5, "adam": 1, "adam_epsilon": [1, 7], "add": [0, 1], "addit": 5, "adher": 5, "affect": 5, "agent": [3, 5], "aggreg": 5, "all": [1, 5], "alloc": 5, "allow": 3, "alpha": 1, "alreadi": 6, "also": 5, "altern": 3, "an": [1, 3, 5, 6], "analysi": 5, "analyz": 5, "ani": [1, 6], "anoth": 6, "answer": [1, 5, 6], "answer_extract": [1, 7], "answer_format_instruct": [1, 7], "answer_format_instruction_dir": [1, 7], "anywai": 6, "append": [1, 5, 6], "appropri": 5, "ar": [1, 3, 5, 6], "arg": 6, "argument": [1, 6], "ask": 3, "aspect": [3, 5], "assertionerror": 5, "assesor": 6, "assess": 5, "assessor": [1, 5, 6], "assessor_transcript": [1, 5, 6], "assign": [5, 6], "associ": 5, "assum": 5, "attr_nam": 1, "attrbut": 1, "attribut": [1, 5], "auto": 6, "autom": 5, "automat": 5, "autotoken": [4, 6], "avail": 5, "back": 1, "base": [1, 3, 4, 5, 6], "base_language_aspect": [1, 7], "base_model": [1, 5, 7], "base_task": [1, 7], "basemodel": [1, 3, 4, 5, 6], "batch": [1, 5, 6], "batch_id": 6, "batch_prompt_data": [5, 6], "batch_siz": [1, 6, 7], "batchize_convers": [1, 4], "batchpromptdata": [1, 5, 6], "beam": 1, "becaus": 6, "been": [3, 6], "befor": 5, "begin": 6, "being": 6, "below": 3, "benchmark": 7, "between": [3, 5], "bia": 1, "bo": 1, "bodi": 5, "bool": [1, 3, 5, 6], "boolean": 6, "bos_token_id": [1, 7], "both": 5, "calcul": 5, "call": 5, "callabl": 1, "caller": 5, "can": [1, 5], "cannot": 6, "cf": 5, "chain": 5, "check": [1, 5, 6], "check_scor": [1, 5, 6], "choic": 1, "cl": 1, "class": [1, 3, 4, 5, 6], "classmethod": 1, "combin": 5, "come": 6, "common": [1, 7], "compar": 5, "compat": [3, 5], "compatible_task": [1, 3, 5], "complet": [5, 6], "comput": 5, "config": [6, 7], "configload": [1, 7], "configur": [1, 5], "consid": 5, "constraint": 5, "construct": 5, "contain": [1, 3, 5, 6], "content": [0, 7], "context": 5, "convers": 5, "conversations_list": 4, "convert": 5, "convert_batch_prompt_into_conversation_templ": [1, 5], "copi": 5, "correct": 5, "correspond": 5, "cot": [1, 3, 5, 6], "cot_evalu": 7, "cot_instruct": [1, 5], "cot_prompt": [1, 5, 6], "cot_transcript": [1, 6], "cotgapsummari": [1, 6], "could": 6, "creat": [1, 5, 6], "create_ref_model": [1, 7], "creation": 6, "csv": 5, "cuda": 6, "custom": 5, "data": [1, 5], "dataclass": 1, "datainfo": [1, 6], "dataload": 6, "dataset": [1, 5, 7], "dataset_class_kwarg": [1, 6, 7], "dataset_class_nam": [1, 6, 7], "decai": 1, "decreas": 5, "deepseek": [1, 7], "deepseek_r1_1pt5b": [1, 4], "default": [1, 5], "defin": [3, 5, 6], "delet": 1, "depend": 5, "deriv": 5, "descript": [3, 7], "detail": [0, 5], "detect": 3, "determin": 5, "devic": [4, 6], "dict": [1, 4, 5, 6], "dictionari": 1, "differ": 5, "directori": 1, "discard": 5, "do": 6, "do_sampl": [1, 7], "doe": [3, 5, 6], "doesn": 3, "doubl": 6, "dropout": 1, "duplic": [1, 4], "e": 5, "each": [1, 3, 5], "easili": 3, "either": 6, "element": 6, "elicitng": 5, "emptylanguageaspect": [1, 3], "enabl": 5, "encourag": 5, "end": [1, 6], "end_output_token": [1, 7], "end_output_token_dir": [1, 7], "end_scratchpad_token": [1, 7], "end_scratchpad_token_dir": [1, 7], "ensur": 5, "entri": [1, 5], "eo": 1, "eos_token_id": [1, 7], "episod": [1, 5], "epoch": 1, "epsilon": 1, "error": [1, 6], "evalu": [1, 5], "evaluate_cot_gap": [1, 7], "evaluate_cot_gap_summari": [1, 6], "everyth": 1, "examin": 3, "exampl": [1, 3, 5], "exce": 5, "except": [1, 7], "exclud": 5, "expect": 6, "experi": 1, "experimentarg": [1, 7], "explicitli": 5, "extend": [5, 6], "extra": 5, "extract": [5, 6], "extract_boolean_overseer_or_assessor_answ": [1, 6], "extract_cot": [1, 6], "extract_floatingpoint_overseer_or_assessor_answ": [1, 6], "extract_neural_assessor_answ": [1, 5, 6], "extract_neural_overseer_answ": [1, 6], "extract_sect": [1, 6], "extracted_assessor_answ": [1, 6], "extracted_cot": [1, 6], "extracted_final_answer_with_cot": [1, 6], "extracted_final_answer_without_cot": [1, 6], "extracted_overseer_answ": [1, 6], "facilit": 5, "fail": 6, "fals": [3, 5, 6], "file": [1, 5], "file_path": 1, "final": 5, "find": 3, "fix": 5, "fixeddatasetdatainfo": [1, 5, 6], "float": [1, 3, 5, 6], "folder": 1, "follow": 1, "format": [1, 5, 6], "found": 1, "framework": 5, "frequenc": 1, "from": [1, 3, 5, 6], "from_cot_prompt": 5, "from_fil": [1, 7], "from_yaml": [1, 7], "full": 6, "full_gener": [1, 4], "function": 5, "g": 5, "game": [3, 5], "gamebasedtask": [1, 5], "gap": [1, 5], "gener": [1, 5], "generalis": 6, "generate_full_prompt": [1, 5], "generate_info": [1, 5], "generate_prompt": [1, 5], "generate_ref_respons": [1, 7], "generation_config": [1, 4, 6], "generation_kwarg": 6, "generationconfig": [1, 4, 6, 7], "get": [1, 4, 6], "get_assessor_generated_answ": [1, 5], "get_batch_job": [1, 6], "get_dataloaders_and_ref_model": [1, 6], "get_devic": [1, 6], "get_info_from_batch_el": [1, 6], "get_language_scor": [1, 3, 5], "get_messag": [1, 4], "get_model": [1, 4, 6], "get_optim": [1, 6], "get_rewards_and_training_data": [1, 6], "get_task_scor": [1, 5], "get_token": [1, 6], "get_true_answers_from_batch_prompt_data": [1, 5], "give": [1, 6], "given": [5, 6], "gpt": [1, 6, 7], "gpt2model": [1, 4], "gradient": 1, "gradient_accumulation_step": [1, 7], "greater": 5, "ground": 5, "ha": 3, "hacki": 1, "handl": 5, "have": 6, "here": 6, "higher": [3, 5], "him": 1, "howev": 6, "huggingfac": 1, "i": [1, 3, 5, 6], "id": 1, "idx": [1, 5, 6], "imbu": 6, "implement": [3, 5], "import": 5, "improv": 6, "includ": [3, 5, 6], "incompat": 5, "increas": 5, "index": [1, 5, 6], "indic": [5, 6], "individu": 5, "induc": 5, "infer": 5, "info": [1, 6], "inform": [1, 5], "initi": 5, "initialis": 1, "input": [5, 6], "instanc": 5, "instruct": [1, 5], "int": [1, 5, 6], "integr": 5, "intend": 3, "is_equiv": [1, 6], "issu": 5, "jsonl_batch_fil": 6, "jsonl_lin": [1, 6], "just": 6, "k": 1, "keyword": 1, "kwarg": 3, "l_weight": 5, "languag": [1, 5, 7], "language_aspect": 5, "language_scor": 5, "languageaspect": [1, 3, 5], "later": [1, 5], "layer": 1, "learn": 1, "learning_r": [1, 7], "length": [1, 5, 6], "length_sampl": [1, 7], "less": 6, "level": 5, "librari": 1, "limit": 5, "list": [4, 5, 6], "llama": [1, 7], "llama_31_8b_instruct": [1, 4], "llama_32_1b_instruct": [1, 4], "llm": [1, 3, 5], "llmtranscriptextractionerror": [1, 5, 6], "load": 1, "load_config": [1, 7], "load_model": [1, 4], "load_precision_mod": [1, 7], "load_yaml": [1, 7], "loader": [1, 7], "local": 5, "log": 1, "log_load": [1, 4], "log_with": [1, 7], "look": 5, "lora": [1, 7], "lora_alpha": [1, 7], "lora_bia": [1, 7], "lora_dropout": [1, 7], "lora_param": [1, 7], "lora_r": [1, 7], "made": 5, "mai": 5, "main": 5, "make_jsonl_batch_fil": [1, 6], "map": 1, "mar": 5, "market": 3, "math": [3, 5], "math_equival": [1, 7], "math_torch_dataset_task": 5, "mathemat": 5, "max_grad_norm": [1, 7], "max_new_token": [1, 7], "maximum": 1, "md": 5, "mean": 6, "metadata": 5, "method": [1, 3, 5], "methodnam": 6, "metric": 5, "might": 3, "min_length": [1, 7], "mini": [1, 6], "mini_batch_s": [1, 7], "minimum": 1, "mode": [1, 5], "model": [1, 3, 5, 6, 7], "model_class": 6, "model_config": [1, 4, 6], "model_nam": [1, 6, 7], "model_output": 6, "model_save_path": [1, 7], "modelconfig": [1, 4, 6, 7], "modifi": 5, "modul": 7, "more": [1, 3, 5], "move": 5, "multipl": 3, "must": [3, 5], "mustafa": 3, "na": 6, "name": [3, 7], "need": [5, 6], "network": 5, "neural": [1, 5, 6], "neural_assessor": [1, 7], "neural_assessor_from_batch_prompt_data": [1, 5], "neural_assessor_model": 6, "neural_assessor_model_test": 7, "neural_assessor_system_prompt": [1, 7], "neural_assessor_system_prompt_dir": [1, 7], "neural_assessor_user_prompt_templ": [1, 7], "neural_assessor_user_prompt_template_dir": [1, 7], "neural_overseer_model": 6, "neural_overseer_system_prompt": [1, 7], "neural_overseer_system_prompt_dir": [1, 7], "neural_overseer_user_prompt_templ": [1, 7], "neural_overseer_user_prompt_template_dir": [1, 7], "new": [1, 5], "no_cot_instruct": [1, 5, 7], "no_cot_instruction_dir": [1, 7], "no_cot_prompt": [1, 5, 6], "no_cot_transcript": [1, 6], "none": [1, 4, 5, 6], "norm": 1, "normal": 5, "note": [1, 5], "notimplementederror": 5, "num_beam": [1, 7], "num_eval_episod": [1, 7], "num_train_epoch": [1, 7], "number": [1, 3, 5], "number_of_evalu": [1, 7], "number_shared_layers_for_ref_model": [1, 6, 7], "object": [1, 3, 4, 5, 6], "one": 5, "onli": 5, "openai_api_help": [1, 7], "optim": [1, 6], "optimizer_config": [1, 6], "optimizer_nam": [1, 7], "optimizerconfig": [1, 6, 7], "option": [1, 5], "otherwis": 5, "out": [5, 6], "outfil": 6, "output": [1, 6], "output_delimitation_token": [4, 6], "output_end": 6, "output_fil": 6, "output_start": 6, "overrid": [1, 5], "overridden": 5, "override_create_ref_model": 6, "overs": [1, 3, 6], "overseer_transcript": [1, 6], "p": 1, "p1": 3, "p1_bid": [1, 6], "p2_true_cost": [1, 6], "packag": 7, "pad": 1, "pad_token_id": [1, 7], "paramet": [1, 5], "pars": 6, "parse_model_output": [1, 6], "partit": 5, "path": [1, 5], "penalis": [1, 3], "penalisation_class_kwarg": [1, 6, 7], "penalisation_class_nam": [1, 6, 7], "penalti": 5, "perform": 5, "place": 5, "plai": 3, "plot": [1, 7], "plug": 3, "portion": 5, "posit": 6, "potenti": 6, "ppo": 1, "ppo_epoch": [1, 7], "ppo_train": 6, "precis": 1, "prepar": 5, "prevent": 5, "price": 3, "primarili": 5, "problem": [3, 5], "problemsolutionassessor": [1, 5], "process": 5, "produc": 5, "prompt": [1, 3, 5, 6], "prompt_config": [5, 6], "prompt_data": [1, 3, 5, 7], "prompt_data_collate_fn": [1, 5], "promptconfig": [1, 5, 6, 7], "promptconfigload": [1, 7], "promptdata": [1, 3, 5, 6], "properti": [1, 3, 5, 6], "proport": [1, 5], "provid": 5, "prune": [5, 6], "put": 1, "py": 7, "pytorch": 5, "qualiti": 5, "query_tensor": 6, "r": 1, "rais": [5, 6], "random": 5, "rang": [3, 5], "rate": [1, 5], "read_batch_output_fil": [1, 6], "readm": 5, "reason": 5, "recruit": 5, "recruit_neural_assessor": [1, 5], "recruit_neural_overs": [1, 3], "ref": 6, "refer": [1, 3, 6], "reflect": 5, "regex": 6, "relat": 5, "remain": [1, 5], "replac": 1, "replic": 6, "reproduc": 5, "req_id": 6, "request_id": 6, "requir": [3, 5, 6], "respons": [1, 5, 6], "response_text": 6, "restructuredtext": 0, "ret": 6, "retriev": 5, "return": [1, 3, 5, 6], "return_prompt": [1, 7], "reward": [1, 5], "reward_from_transcript": [1, 5], "right": 6, "round": 6, "runtest": 6, "same": 3, "sampl": [1, 5], "sampler": 1, "save": [1, 6], "save_config": [1, 7], "save_frequ": [1, 7], "savefil": 6, "scenario": 5, "score": [1, 3, 5, 7], "score_nam": 6, "score_valu": 6, "scratchpad": 1, "scratchpad_reason": 6, "section": 6, "see": [0, 1, 3, 5], "seed": [1, 5, 6, 7], "select": 5, "self": [1, 5], "send": 3, "separ": [3, 5], "sequentialpricetaskdatainfo": [1, 6], "serv": 5, "set": [3, 5], "set_se": [1, 6], "sever": 5, "share": 1, "should": [3, 5, 6], "shuffl": 5, "sign": 3, "singl": 5, "single_queri": [1, 6], "size": [1, 5], "so": 6, "solut": 5, "solv": 6, "some": [5, 6], "specif": 5, "specifi": 5, "spit": 6, "split": 5, "standard": 5, "start": [1, 6], "start_output_token": [1, 7], "start_output_token_dir": [1, 7], "start_scratchpad_token": [1, 7], "start_scratchpad_token_dir": [1, 7], "start_section_token": 6, "static": 1, "steg": 5, "steganographi": 5, "step": 1, "str": [1, 3, 4, 5, 6], "str1": 6, "str2": 6, "strategi": 5, "string": [5, 6], "strip": 6, "structur": 5, "subclass": [3, 5], "submit_batch_fil": [1, 6], "submodul": 7, "subpackag": 7, "success": 5, "successfulli": 5, "suitabl": 5, "sum_exampl": [1, 6], "sum_extracted_with_cot": [1, 6], "sum_extracted_without_cot": [1, 6], "sum_reward_with_cot": [1, 6], "sum_reward_without_cot": [1, 6], "summari": [1, 6], "super": 1, "supplementari": 5, "support": 5, "suppress": 5, "surround": 6, "syntax": 0, "system": [1, 5, 6], "system_prompt": [1, 4, 5, 6], "t": 3, "t_weight": 5, "take": 6, "task": [1, 3, 6, 7], "task_descript": [1, 7], "task_description_dir": [1, 7], "task_exampl": [1, 7], "task_examples_dir": [1, 7], "task_scor": 5, "temperatur": [1, 6, 7], "templat": [1, 5], "tensortyp": 6, "test": 5, "test_equiv_decimal_fract": [1, 6], "test_equiv_format": [1, 6], "test_equiv_symbol": [1, 6], "test_multiple_answers_1": [1, 6], "test_multiple_answers_2": [1, 6], "test_multiple_answers_3": [1, 6], "test_multiple_answers_4": [1, 6], "test_multiple_answers_5": [1, 6], "test_multiple_answers_6": [1, 6], "test_train_split": [1, 5], "testcas": 6, "testnorm": [1, 6], "text": [1, 5], "than": 6, "them": 5, "thi": [1, 3, 5, 6], "those": 1, "thought": 5, "through": 5, "time": 3, "to_dict": [1, 7], "to_generation_dict": [1, 7], "to_training_dict": [1, 7], "todo": [1, 5, 6], "token": [1, 4, 6], "tokenization_auto": 6, "tool": 1, "top": 1, "top_k": [1, 7], "top_p": [1, 7], "torchdatasettask": [1, 5, 6], "total": 5, "train": [1, 5, 6], "train_config": 1, "train_dataset": 6, "train_dataset_task": 7, "train_proport": [1, 5, 6, 7], "trainconfig": [1, 7], "trainer": 1, "training_model": 6, "transcript": 5, "transcript_respons": 6, "transform": [1, 6], "transform_convers": [1, 4], "true": [5, 6], "true_answ": 5, "truth": 5, "tupl": [1, 5, 6], "turn": 5, "type": [1, 5, 6], "typeerror": 5, "u": 3, "uniqu": 5, "unsuccess": 5, "up": 5, "updat": 5, "us": [0, 1, 3, 5], "usag": 5, "user": [1, 5], "user_prompt": [4, 5, 6], "user_str": 4, "uses_local_neural_assessor": [1, 5], "uses_local_neural_overs": [1, 3], "util": [1, 5, 7], "valid": [1, 5], "validation_proport": [1, 5, 6, 7], "valu": [1, 5, 6], "valueerror": 6, "variabl": [1, 5], "variant": 5, "verbos": 6, "version": 5, "wa": [3, 5, 6], "wandb": 1, "warmup": 1, "warmup_step": [1, 7], "warn": 5, "we": [3, 6], "weight": [1, 5], "weight_decai": [1, 7], "well": 6, "were": 5, "when": [1, 5], "where": 5, "whether": [1, 3, 5], "which": [3, 5, 6], "whitebox_model": [4, 5], "whitespac": 6, "win": 5, "with_cot": 5, "with_cot_instruct": [1, 7], "with_cot_instruction_dir": [1, 7], "within": 5, "work": 6, "xxx": 1, "yaml": 1, "yaml_fil": 1, "you": 3, "your": 0, "zero": 3}, "titles": ["MARS Steg documentation", "mars_steg package", "mars_steg.dataset package", "mars_steg.language package", "mars_steg.model package", "mars_steg.task package", "mars_steg.utils package", "mars_steg"], "titleterms": {"answer_extract": 6, "base_language_aspect": 3, "base_model": 4, "base_task": 5, "benchmark": 1, "common": 6, "config": 1, "content": [1, 2, 3, 4, 5, 6], "cot_evalu": 1, "dataset": 2, "deepseek": 4, "descript": [1, 5], "document": 0, "except": 6, "gpt": 4, "languag": 3, "llama": 4, "loader": 4, "mar": 0, "mars_steg": [1, 2, 3, 4, 5, 6, 7], "math_equival": 6, "model": 4, "modul": [1, 2, 3, 4, 5, 6], "name": [1, 5], "neural_assessor": 5, "neural_assessor_model_test": 1, "openai_api_help": 6, "packag": [1, 2, 3, 4, 5, 6], "plot": 6, "prompt_data": 6, "py": [1, 5], "score": 6, "steg": 0, "submodul": [1, 3, 4, 5, 6], "subpackag": 1, "task": 5, "train_dataset_task": 1, "util": 6}})